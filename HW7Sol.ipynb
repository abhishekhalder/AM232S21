{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. [50 points] Discrete Time Finite Horizon DP \n",
    "\n",
    "Before start solving this problem, please review Lec. 16, p. 4-8.\n",
    "\n",
    "Given a controlled dynamical system\n",
    "\n",
    "$$x_{k+1} = x_{k} + u_{k}, \\quad u_{k}\\in\\{-1,0\\}, \\quad k=0,1,$$\n",
    "\n",
    "with the initial condition $x_{0} \\equiv 1$. Consider the problem\n",
    "\n",
    "$$\\underset{\\gamma\\in\\Gamma}{\\text{minimize}}\\quad\\alpha\\left(x_{1}^{2}+x_{2}^{2}\\right) + (1-\\alpha)\\left(u_{0}^{2} + u_{1}^{2}\\right)$$\n",
    "\n",
    "subject to the above dynamics, where $\\Gamma$ is the collection of all history dependent randomized policies, and $\\alpha$ is a given constant satisfying $0\\leq \\alpha \\leq 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [(2+2+2) + (3+3+3) = 15 points] State space and costs\n",
    "\n",
    "(i) Clearly write down the state space $\\mathcal{X}_{k}$ for each $k=0,1,2$.\n",
    "\n",
    "(ii) Looking at the objective, clearly write down the costs $c_{k}$ for each $k=0,1,2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for Problem 1(a):\n",
    "\n",
    "(i)<img src=\"FigStateSpace.jpg\" width=\"600\">\n",
    "\n",
    "To derive the state spaces $\\mathcal{X}_{k}$, we draw a tree rooted at $\\mathcal{X}_{0}=\\{1\\}$ (given) as shown in the figure above. This gives $\\mathcal{X}_{0}=\\{1\\}$, $\\mathcal{X}_{1}=\\{0,1\\}$, $\\mathcal{X}_{2}=\\{-1,0,1\\}$.\n",
    "\n",
    "(ii) We rewrite the given objective in the standard form:\n",
    "\n",
    "$$\\alpha\\left(x_{1}^{2}+x_{2}^{2}\\right) + (1-\\alpha)\\left(u_{0}^{2} + u_{1}^{2}\\right) = c_{2}(x_{2}) + \\displaystyle\\sum_{k=0}^{2-1}c_{k}(x_{k},u_{k}).$$\n",
    "\n",
    "From the above, we identify $c_{0}(x_{0},u_{0})= (1-\\alpha)u_{0}^{2}$, $c_{1}(x_{1},u_{1})=\\alpha x_{1}^{2} + (1-\\alpha)u_{1}^{2}$, $c_{2}(x_{2}) = \\alpha x_{2}^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [35 points] Optimal cost-to-go\n",
    "\n",
    "Apply DP recursions to compute the optimal cost-to-go (a.k.a. value function) $V_{0}$. Your final answer should be in the form:\n",
    "\n",
    "$$V_{0} = \\begin{cases}\n",
    "f(\\alpha) & \\text{if}\\quad\\alpha\\leq\\alpha_{0},\\\\\n",
    "g(\\alpha) & \\text{if}\\quad\\alpha > \\alpha_{0},\n",
    "\\end{cases}$$\n",
    "\n",
    "where you need to explicitly compute $f(\\cdot),g(\\cdot),\\alpha_{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for Problem 1(b):\n",
    "\n",
    "From DP recursion, $V_{2}(x_{2}) =c_{2}(x_{2})=\\alpha x_{2}^{2}$, and\n",
    "\n",
    "\\begin{align*}\n",
    "V_{1}(x_{1}) &= \\underset{u\\in\\{-1,0\\}}{\\min}\\quad c_{1}(x_{1},u) + V_{2}\\left(x_{1}+u\\right)\\\\\n",
    "&=\\underset{u\\in\\{-1,0\\}}{\\min}\\quad \\alpha x_{1}^{2} + (1-\\alpha)u^{2} + \\alpha(x_{1}+u)^{2}\\\\\n",
    "&= \\min\\{2\\alpha x_{1}^{2}, 2\\alpha x_{1}^{2} - 2\\alpha x_{1} + 1\\}.\n",
    "\\end{align*}\n",
    "Since $x_{1}\\in\\mathcal{X}_{1}=\\{0,1\\}$, we get\n",
    "$$V_{1}(0)=\\min\\{0,1\\}=0,\\quad\\text{and}\\quad V_{1}(1) = \\min\\{2\\alpha,1\\}=\\begin{cases}2\\alpha & \\text{if} \\quad \\alpha \\leq 1/2,\\\\\n",
    "1 & \\text{if} \\quad \\alpha > 1/2.\n",
    "\\end{cases}$$\n",
    "Next,\n",
    "\\begin{align*}\n",
    "V_{0}(x_{0}) &= \\underset{u\\in\\{-1,0\\}}{\\min}\\quad c_{0}(x_{0},u) + V_{1}\\left(x_{0}+u\\right)\\\\\n",
    "&=\\underset{u\\in\\{-1,0\\}}{\\min}\\quad (1-\\alpha) u^{2} + V_{1}(x_{0}+u).\n",
    "\\end{align*}\n",
    "Since $x_{0}\\in\\mathcal{X}_{0}=\\{1\\}$, therefore,\n",
    "\\begin{align*}\n",
    "V_{0}(1) &= \\underset{u\\in\\{-1,0\\}}{\\min}\\quad (1-\\alpha) u^{2} + V_{1}(1+u)\\\\\n",
    "&= \\min\\{1-\\alpha + \\underbrace{V_{1}(0)}_{=0},\\underbrace{V_{1}(1)}_{=\\min\\{2\\alpha,1\\}}\\}\\\\\n",
    "&= \\min\\{1-\\alpha,\\min\\{2\\alpha,1\\}\\}\\\\\n",
    "&= \\begin{cases}\n",
    "\\min\\{1-\\alpha,2\\alpha\\} & \\text{if} \\quad \\alpha \\leq 1/2,\\\\\n",
    "\\underbrace{\\min\\{1-\\alpha,1\\}}_{=1-\\alpha} & \\text{if} \\quad \\alpha > 1/2,\n",
    "\\end{cases}\\\\\n",
    "&= \\min\\{\\min\\{1-\\alpha,2\\alpha\\},1-\\alpha\\}\\\\\n",
    "&= \\min\\{1-\\alpha,2\\alpha\\}\\\\\n",
    "&= \\begin{cases}\n",
    "2\\alpha & \\text{if} \\quad \\alpha \\leq 1/3,\\\\\n",
    "1-\\alpha & \\text{if} \\quad \\alpha > 1/3.\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "Hence $f(\\alpha)=2\\alpha$, $g(\\alpha)=1-\\alpha$, $\\alpha_{0}=1/3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. [50 points] Continuous Time DP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [25 points] \n",
    "\n",
    "Suppose we have a continuous time DP problem given by the HJB PDE initial value problem\n",
    "\n",
    "$$\\dfrac{\\partial V}{\\partial\\tau} + H_{\\text{opt}}\\left(P\\dfrac{\\partial V}{\\partial x} + q\\right)=0, \\qquad V(\\tau=0,x) = \\phi(x), \\quad x\\in\\mathbb{R}^{n},$$\n",
    "\n",
    "where $H_{\\text{opt}}(z)$ is a convex and 1-coercive function of $z\\in\\mathbb{R}^{n}$. The matrix $P\\succ 0$, and the vector $q\\in\\mathbb{R}^{n}$ are given. \n",
    "\n",
    "Derive a Hopf-Lax formula for the solution $V(\\tau,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for Part 2(a):\n",
    "\n",
    "Since all conditions stated in Lec. 19, p. 18-19, are satisfied in this case, we can use the Hopf-Lax formula in Lec. 20, p. 1, applied to the affine composition $H_{\\text{opt}}(P\\xi + q)$.\n",
    "\n",
    "Suppose that the Legendre-Fenchel conjugate $\\left(H_{\\text{opt}}(\\xi)\\right)^{*} = H_{\\text{opt}}^{*}(\\eta)$. Then, from Lec. 20, p. 2, it follows that\n",
    "\n",
    "$$\\left(H_{\\text{opt}}(P\\xi + q)\\right)^{*} = H_{\\text{opt}}^{*}(P^{-\\top}\\eta) - \\langle q, P^{-\\top}\\eta\\rangle = H_{\\text{opt}}^{*}(P^{-1}\\eta) - \\langle q, P^{-1}\\eta\\rangle \\quad\\text{since}\\;P\\succ 0.$$\n",
    "\n",
    "See also p. 2 of the posted supplementary notes \"CalculusOfConvexConjugates.pdf\".\n",
    "\n",
    "Therefore, the Hopf-Lax formula in this case becomes\n",
    "\\begin{align*}\n",
    "V(\\tau,x) &= \\underset{y\\in\\mathbb{R}^{n}}{\\min}\\quad\\phi(y) + \\tau H_{\\text{opt}}^{*}\\left(P^{-1}\\frac{x-y}{\\tau}\\right) - \\tau\\bigg\\langle q, P^{-1}\\frac{x-y}{\\tau}\\bigg\\rangle\\\\\n",
    "&= \\underset{y\\in\\mathbb{R}^{n}}{\\min}\\quad\\phi(y) + \\tau H_{\\text{opt}}^{*}\\left(P^{-1}\\frac{x-y}{\\tau}\\right) - \\bigg\\langle q, P^{-1}(x-y)\\bigg\\rangle.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [25 points] \n",
    "\n",
    "Consider the continuous time OCP\n",
    "$$\\underset{\\gamma\\in\\Gamma}{\\text{minimize}}\\quad \\| x(T) \\|_{2} + \\int_{0}^{T}\\frac{1}{2}\\|u\\|_{2}^{2}\\:{\\rm{d}}t$$\n",
    "\n",
    "subject to $\\dot{x} = u$, where $x\\in\\mathbb{R}^{n}$. Prove that the value function is of the form\n",
    "\n",
    "$$V(t,x) = \\begin{cases}\n",
    "a(t,x) & \\text{if} \\quad \\|x\\|_{2} \\leq T-t,\\\\\n",
    "b(t,x) & \\text{if} \\quad \\|x\\|_{2} > T-t. \n",
    "\\end{cases}$$\n",
    "\n",
    "Explicitly determine the functions $a(t,x)$ and $b(t,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part 2(b):\n",
    "\n",
    "Proceeding as in Lec. 20, p. 3-5, we arrive at the HJB PDE IVP:\n",
    "\n",
    "$$\\dfrac{\\partial V}{\\partial \\tau} + \\dfrac{1}{2}\\:\\bigg\\|\\dfrac{\\partial V}{\\partial x}\\bigg\\|_{2}^{2} = 0, \\quad V(\\tau=0,x) = \\|x\\|_{2},$$\n",
    "\n",
    "where $\\tau:=T-t > 0$, and the Hopf-Lax formula becomes\n",
    "$$V(\\tau,x) = \\underset{y\\in\\mathbb{R}^{n}}{\\min}\\quad \\|y\\|_{2} + \\dfrac{1}{2\\tau}\\|x-y\\|_{2}^{2} = M_{\\|\\cdot\\|_{2}}^{\\tau}(x) \\quad \\text{(the Moreau-Yosida envelope of $\\|\\cdot\\|_{2}$).}$$\n",
    "\n",
    "To explcitly compute the argmin $y_{\\text{opt}}:=\\text{prox}_{\\tau\\|\\cdot\\|_{2}}(x)$ of the above unconstrained convex minimization problem, we observe from the definition of prox operator that $y_{\\text{opt}} = 0$ if $x=0$. To determine $y_{\\text{opt}}$ when $x\\neq 0$, we take the derivative of the objective and set it equal to zero to get\n",
    "\n",
    "$$\\left(\\dfrac{\\tau}{\\|y_{\\text{opt}}\\|_{2}} + 1\\right)y_{\\text{opt}} = x, \\quad x\\neq 0. \\qquad\\qquad (*)$$\n",
    "\n",
    "Applying $\\|\\cdot\\|_{2}$ to both sides of the above, we obtain $\\|y_{\\text{opt}}\\|_{2} = \\|x\\|_{2}-\\tau$ provided $\\|x\\|_{2}\\geq\\tau$ since $\\|y_{\\text{opt}}\\|_{2}$ must be nonnegative. Therefore, $(*)$ gives\n",
    "$$y_{\\text{opt}} = \\left(1 - \\dfrac{\\tau}{\\|x\\|_{2}}\\right)x, \\quad x\\neq 0, \\quad \\|x\\|_{2}\\geq \\tau.$$\n",
    "Combining the $x=0$ and $x\\neq 0$ cases, we get\n",
    "\\begin{align*}\n",
    "y_{\\text{opt}} = \\text{prox}_{\\tau\\|\\cdot\\|_{2}}(x) &= \\begin{cases}\n",
    "\\left(\\|x\\|_{2}-\\tau\\right)_{+}\\dfrac{x}{\\|x\\|_{2}}, & \\text{if}\\quad x\\neq 0,\\\\\n",
    "0, & \\text{if} \\quad x=0,\n",
    "\\end{cases}\\\\\n",
    "&= \\left(1 - \\dfrac{\\tau}{\\max\\{\\|x\\|_{2},\\tau\\}}\\right)x, \\qquad\\qquad (**)\n",
    "\\end{align*}\n",
    "wherein $(z)_{+} := \\max\\{z,0\\}$.\n",
    "\n",
    "Substituting the minimizer $(**)$ back in the objective (as in Lec. 20, p. 7), we obtain the minimum value\n",
    "\\begin{align*}\n",
    "M_{\\|\\cdot\\|_{2}}^{\\tau}(x) &= \\|\\text{prox}_{\\tau\\|\\cdot\\|_{2}}(x)\\|_{2} + \\dfrac{1}{2\\tau}\\|x - \\text{prox}_{\\tau\\|\\cdot\\|_{2}}(x)\\|_{2}^{2}\\\\\n",
    "&= \\begin{cases} \\dfrac{1}{2\\tau}\\|x\\|_{2}^{2} & \\text{if} \\quad \\|x\\|_{2} \\leq \\tau,\\\\\n",
    "\\|x\\|_{2} - \\dfrac{\\tau}{2} & \\text{if} \\quad \\|x\\|_{2} > \\tau,\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "which is the Huber function well-known in machine learning.\n",
    "\n",
    "Recalling that $\\tau := T-t$, the statement follows with\n",
    "$$a(t,x) = \\dfrac{1}{2(T-t)}\\|x\\|_{2}^{2}, \\quad b(t,x) = \\|x\\|_{2} - \\dfrac{T-t}{2}.$$\n",
    "\n",
    "A plot of the corresponding value functions is shown below for $T = 50$ and state space $[-0.5,0.5]^{2}$; notice the time-dependent switching of the shape of $V$ as pedicted above.\n",
    "\n",
    "<img src=\"ValueFunctionsProb2b.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
